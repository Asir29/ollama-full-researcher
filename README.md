# ğŸ§  Ollama CodeEval Researcher

**Ollama CodeEval Researcher** is a fully local **coderâ€“evaluator and research assistant** powered by any LLM hosted via [Ollama](https://ollama.com/search).

Originally forked from [CopilotKit/ollama-deep-researcher](https://github.com/CopilotKit/ollama-deep-researcher), this enhanced version extends the original web research concept with **academic exploration** and **autonomous code generation + evaluation**.

---

## ğŸ¯ Core Capabilities

The CodeEval Researcher can perform three main types of tasks:

1. ğŸŒ **General Web Research** â€” deep information gathering across the internet.  
2. ğŸ“š **Academic Source Research** â€” exploration of scholarly papers and databases.  
3. ğŸ’» **Code Generation & Evaluation** â€” autonomous code creation, static analysis, and sandboxed execution.

---

## ğŸ¬ Demo

![Demo Preview](./assets/gif_exec.gif)

In this demo, you can see:
- A query related to **snnTorch**
- **Code generation** followed by **static evaluation**
- A **user-requested fix**
- The **final successful execution** of the corrected code

---

## ğŸš€ Quickstart

### ğŸªŸ Windows Installation (with Conda)

1. Create the environment  
   â†’ `conda env create -f environment.yaml`  

2. Activate the environment  
   â†’ `conda activate ollama_full_research`  

3. From the project directory, start the development server  
   â†’ `langgraph dev --no-reload`

---

### ğŸ§© Installing New Modules

1. Find your environment path  
   â†’ `conda env list`  

2. Install the desired package  
   â†’ `path/to/your/env/bin/python -m pip install <package-name>`  

3. Verify the installation  
   â†’ `conda list`

---

## ğŸ¦™ Ollama Setup

<img src="./assets/ollama.png" alt="Ollama Logo" width="100"/>

### ğŸ“¦ Install Ollama  
Follow the official installation guide:  
ğŸ‘‰ [https://ollama.com/download](https://ollama.com/download)

---

### ğŸ§­ Start the Ollama Server  
Open a terminal and run:  
â†’ `ollama serve`

---

### ğŸ¤– Pull the Required Models  
Run these commands to download the models used in this project:  
â†’ `ollama pull qwen3:latest`  
â†’ `ollama pull deepseek-r1:latest`  
â†’ `ollama pull gpt-oss:20b`  
â†’ `ollama pull mistral:latest`

---

### ğŸ§¾ List Installed Models  
To see all installed models:  
â†’ `ollama list`

---

## ğŸ” Tavily Setup

To use the Tavily to perform web researches, you only need an **API key** from [tavily](https://www.tavily.com/).

1. Get your API key from [https://www.tavily.com/](https://www.tavily.com/).  
2. Create a `.env` file in the **root directory** of the project (if it doesnâ€™t exist).  
3. Add your key like this:  
   `TAVILY_API_KEY="your_api_key_here"`

---

## ğŸ§ª Sandbox Environment Setup

To use the sandbox, you only need an **API key** from [e2b.dev](https://e2b.dev/).

1. Get your API key from [https://e2b.dev/](https://e2b.dev/).  
2. Create a `.env` file in the **root directory** of the project (if it doesnâ€™t exist).  
3. Add your key like this:  
   `E2B_API_KEY="your_api_key_here"`

---

## âš™ï¸ How It Works

The **Ollama CodeEval Researcher** operates through three interconnected branches, coordinated by a state machine. Each branch focuses on a specific task type:

---

### ğŸŒ 1. Web Research Branch
Responsible for general web exploration:  
- Generates optimized search queries using LLMs  
- Gathers and summarizes online content  
- Performs reflective reasoning to refine searches and deepen analysis  

---

### ğŸ“š 2. Academic Research Branch
Handles scholarly and scientific research:  
- Queries academic APIs such as Google Scholar and Semantic Scholar  
- Builds a semantic index of papers for context-aware retrieval  
- Summarizes findings into concise insights  

---

### ğŸ’» 3. Code Generation & Evaluation Branch
Focused on code creation, analysis, and execution:  
- Builds and maintains a **vectorstore** from documentation (e.g., snnTorch)  
- Performs **Retrieval-Augmented Generation (RAG)** for context-aware coding  
- Executes **static analysis** and **safe sandbox evaluation**  
- Detects and installs missing dependencies automatically  
- Runs code in a **secure isolated environment**  
- Learns from feedback to iteratively improve generated solutions  

---

## ğŸ–¥ï¸ Frontend Visualization

To visualize the systemâ€™s workflow with **LangGraphâ€™s frontend**, run:  
â†’ `langgraph dev`

âš ï¸ *Note:* The current version does **not** include a custom frontend implementation.

---

## ğŸ’¡ Summary

| Feature | Description |
|----------|--------------|
| ğŸ”’ **Local-first** | Runs entirely on your machine via Ollama |
| ğŸ§  **Intelligent Research** | Web + academic data synthesis |
| ğŸ’» **Code Capabilities** | Autonomous code generation and evaluation |
| ğŸ§ª **Safe Execution** | Secure sandboxing powered by [e2b.dev](https://e2b.dev/) |

---

## âœ¨ Credits

- Forked from [CopilotKit/ollama-deep-researcher](https://github.com/CopilotKit/ollama-deep-researcher)  
- Enhanced to include **academic research**, **code generation**, and **evaluation mechanisms**

---
